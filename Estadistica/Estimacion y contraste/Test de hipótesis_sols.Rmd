---
title: "Test de hipótesis"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, out.width="50%", fig.align = "center")
# Librerías necesarias
library(tidyverse)
theme_set(theme_classic())
library("pwr")
library(effectsize)
library(performance)
library(EnvStats)
library(readr)
library(readxl)
```

## Introducción teórica.

Los test de hipótesis son una herramienta estadística que se utiliza para *demostrar* o *refutar* **estadísticamente** determinadas afirmaciones mediante el uso de inferencia sobre una muestra de datos. La forma de proceder es la siguiente:

-   Se formula una **hipótesis nula** $H_0$, esta sentencia es lo contrario a lo que pretendemos *demostrar* (**hipótesis alternativa** $H_a$).

-   Consideramos un **estadístico de contraste** $T$ en relación con la hipótesis nula $H_0$.

-   Calculamos el $p$-valor: según $H_0$, calculamos la probabilidad de obtener un valor del estadístico como los datos de la muestra indican.

-   Si $p < \alpha$, entonces **rechazamos** $H_0$ en favor de $H_a$ con una significancia del $100\cdot\alpha \%$.

La significancia indica la probabilidad de equivocarnos al rechazar la hipótesis nula, pero existen más tipos de errores asociados a un test de hipótesis.

**Tipos de error en un test de hipótesis**:

$$ \begin{array}{|l|cc|} \hline
 & H_0 \text{ es cierta} & H_0 \text{ es falsa} \\ \hline
H_0 \text{ es rechazada} & \text{Error tipo I} & \checkmark \\ 
H_0 \text{ no es rechazada} & \checkmark & \text{Error tipo II} \\ \hline
\end{array}$$

-   La probabilidad de cometer un *falso positivo* (error de tipo I) se denota por $\alpha$ y se llama **confianza del test** a la probabilidad $1-\alpha$.

-   La probabilidad de cometer un *falso negativo* (error de tipo II) se denota por $\beta$ y se llama **potencia del test** a la probabilidad $1-\beta$.

**Tamaño del efecto**. El tamaño del efecto en un test de hipótesis es una medida que indica la magnitud de la diferencia entre dos grupos o condiciones. A diferencia del valor p, que solo nos dice si la diferencia es estadísticamente significativa, el tamaño del efecto nos muestra cuán grande es esa diferencia. Existen varias formas de calcular el tamaño del efecto, dependiendo del tipo de datos y del test estadístico que se esté utilizando, puedes encontrar más información [aquí](https://imaging.mrc-cbu.cam.ac.uk/statswiki/FAQ/effectSize). El tamaño del efecto es importante porque nos ayuda a entender la relevancia práctica de los resultados. Por ejemplo, una diferencia puede ser estadísticamente significativa pero tener un tamaño del efecto muy pequeño, lo que podría indicar que la diferencia no es muy relevante en términos prácticos.

**Informe**. Un informe detallado de un test debe de contener los siguientes datos; tamaño de la muestra, $p$-valor, significancia, potencia, estadístico, intervalo de confianza, tamaño del efecto y asunciones del test.

## Ejercicios

### Test sobre la media de una población.

Un producto homeopático afirma que "gracias a su uso, perderás 2kg en un mes". Escéptico ante esa afirmación, reclutas a 50 personas de tu ciudad para probar el producto, datos en "homeo_weight_loss.csv". Realiza un test de hipótesis (sin conocer la desviación típica poblacional).

Para empezar, accede a los datos y representalos gráficamente como mejor consideres.

```{r}
# Leemos los datos
data = read.csv("homeo_weight_loss.csv")

# Representamos los datos
ggplot(data, aes(x = weight_loss_Kg, y = after_stat(density)))+  
	geom_histogram(bins = 6, fill = "gray", colour = "black")+
  geom_density(lwd = 1)
```

Identifica tu hipótesis nula:

$$ \begin{cases} H_0 : \mu = 2 \\
H_a : \mu \neq 2\end{cases} $$

Para este tipo de test, al desconocer la varianza, necesitamos hacer uso del estadístico $T$. Utiliza `t.test()` para realizar el test de hipótesis con una significancia del 5%.

```{r}
# Realizamos un T-Test
test = t.test(data$weight_loss_Kg, mu = 2, conf.level = 0.95)

test
```

Calcula el tamaño del efecto utilizando `effectsize()`:

```{r}
eff = effectsize(test)
eff
```

Calcula la potencia del test con `pwr.t.test()`:

```{r}
pwr.t.test(n=50, d = eff$Cohens_d, sig.level = 0.05, type = "one")
```

**Informe**. Observamos una normalidad en los datos, por lo que nos disponemos a realizar un test T de Student para contrastar la hipótesis nula de que la media es igual a $2$. Los resultados del T-test de dos colas sobre una muestra de $50$ sujetos evidencian un rechazo sobre la hipótesis nula con un tamaño del efecto mediano en la media de pérdida de peso [$t = -5.25$, $p<0.00001$, $d = 0.74$] con una potencia de $0.999$. De hecho, hemos obtenido el intervalo $(-0.71,0.79)$ para la media con una significancia de $0.05$.

**Conclusión**. Se refuta la utilidad del producto.

Supongamos ahora que la afirmación es "gracias a su uso, perderás al menos 2kg en un mes". Ahora la hipótesis nula ha cambiado:

$$ \begin{cases} H_0 : \mu \geq 2 \\
H_a : \mu < 2\end{cases} $$

Repetimos el test:

```{r}
# Realizamos un T-Test
test = t.test(data$weight_loss_Kg, mu = 2, conf.level = 0.95, alternative = "less")
test

# Tamaño del efecto
eff = effectsize(test)
eff

#Potencia
pwr.t.test(n=50, d = eff$Cohens_d, sig.level = 0.05, type = "one", alternative = "less")
```

**Informe**. Observamos una normalidad en los datos, por lo que nos disponemos a realizar un test T de Student para contrastar la hipótesis nula de que la media mayor o igual a $2$. Los resultados del T-test de dos colas sobre una muestra de $50$ sujetos evidencian un rechazo sobre la hipótesis nula con un tamaño del efecto mediano en la media de pérdida de peso [$t = -5.25$, $p<0.00001$, $d = 0.74$] con una potencia de $0.999$. De hecho, hemos obtenido el intervalo $(-\infty,0.66)$ para la media con una significancia de $0.05$.

**Conclusión**. Se refuta la utilidad del producto.

### Test sobre la varianza de una población.

Los test de cociente intelectual (CI) están diseñados para que la desviación típica poblacional sea de 15 puntos. Sin embargo, en los procesos de traducción de un test "oficial" de CI pueden surgir desajustes. Por ejemplo, "iq_spanish.csv" tiene los resultados de un test de CI traducido del inglés al español. ¿Hay evidencia de que la desviación típica es distinta de 15 y, por tanto, debe revisarse la traducción? Usa un nivel de significación del 5%.

```{r}
data = read.csv("iq_spanish.csv")
```

Visualiza los datos:

```{r}
ggplot(data, aes(x = iq, y = after_stat(density)))+  
	geom_histogram(bins = 8, fill = "gray", colour = "black")+
  geom_density(lwd = 1)
```

Para realizar un test sobre la varianza no existe una función de R base, por lo que hay que utilziar la librería `EnvStats`:

```{r}
test = varTest(data$iq, alternative = "two.sided", sigma.squared = 15^2)
test
```

**Conclusión**: La desviación típica no es 15 con una significancia del 5%. Sin embargo, una significancia del 1% no superaría el test y no podríamos obtener conclusiones, además no hemos podido realizar un informe completo inlcuyendo la potencia...

Genera una simulación para estimar la potencia:

```{r}
# Tamaño de la muestra
n = 30

# Suponemos H0 falsa y consideramos la desviación real *cercana* 
# (ley de los grandes números) a la estimada puntualmente.
sd_real = sqrt(test$estimate)

# Simulaciones
N = 5000

experimentos = replicate(N,{
	# Generamos nuestro experimento	(la media no tiene ninguna influencia)
  datos = rnorm(n, sd = sd_real)

	# Comprobamos nuestro evento (calcular el p-valor del test)
	x = (n-1) * var(datos) / 15^2
	p = 2 * (1-pchisq(x,n-1))
	
	# No se rechaza H0
	p >= 0.05
})
beta = mean(experimentos)

print(paste("Potencia:",1-beta))
```

Prueba a cambiar $n$ hasta obtener una potencia del 90%:

```{r}
# Tamaño de la muestra
n = 70

# Suponemos H0 falsa y consideramos la desviación real *cercana* 
# (ley de los grandes números) a la estimada puntualmente.
sd_real = sqrt(test$estimate)

# Simulaciones
N = 5000

experimentos = replicate(N,{
	# Generamos nuestro experimento	(la media no tiene ninguna influencia)
  datos = rnorm(n, sd = sd_real)

	# Comprobamos nuestro evento (calcular el p-valor del test)
	x = (n-1) * var(datos) / 15^2
	p = 2 * (1-pchisq(x,n-1))
	
	# No se rechaza H0
	p >= 0.05
})
beta = mean(experimentos)

print(paste("Potencia:",1-beta))
```

**Nota**: Puedes calcular la potencia de **cualquier test** mediante simulaciones.

### Cálculo del tamaño de una muestra.

Según estadísticas oficiales, la media de peso de las mujeres de cierto país es de 63.5 Kg (con desviación típica 4.1). Sin embargo, un equipo de investigadores cree que debido a cambios en la alimentación la media se ha incrementado. ¿Cuántas muestras necesitarán para poder detectar un incremento de medio Kg con un nivel de significación del 1% y una potencia del 90%? Utiliza `power.t.test()` (para utilizar `pwr.t.test()` lo que se necesita es el tamaño del efecto)

```{r}
power.t.test(
	delta = 0.5,         # Diferencia entre medias
	sd = 4.1,
	power = 0.9,
	sig.level = 0.01,
	type = "one.sample"
)
```

### Test sobre la media de dos poblaciones.

Los datos contenidos en "howell1.csv" son datos censales parciales del área Kung San compilados a partir de entrevistas realizadas a finales de la década de 1960. ¿Depende la altura de los Kung adultos del sexo del individuo? ($\alpha = 0.01$).

```{r}
# Se necesita librería readr:
data = read_delim("howell1.csv", 
                  delim = ";", 
                  escape_double = FALSE, 
                  trim_ws = TRUE, 
                  show_col_types = F)
```

Plantea el test de hipótesis:

$$ \begin{cases} H_0 : \, \mu _1 = \mu _2 \\ H_a : \, \mu _1 \neq \mu _2  \end{cases} $$

Representa gráficamente los datos de cada muestra:

```{r}
# Hombres
data %>%
  filter(male == 1) %>%
  ggplot(aes(x = height, y = after_stat(density)))+  
	  geom_histogram(bins = 8, fill = "gray", colour = "black")+
    geom_density(lwd = 1, colour = "blue")

# Mujeres
data %>%
  filter(male == 0) %>%
  ggplot(aes(x = height, y = after_stat(density)))+  
	  geom_histogram(bins = 8, fill = "gray", colour = "black")+
    geom_density(lwd = 1, colour = "red")
```

¿Observas algún problema? Las poblaciones no son normales.

Prueba a filtar por mayores de edad (`age` $\geq 18$).

```{r}
# Hombres
data %>%
  filter(age >= 18, male == 1) %>%
  ggplot(aes(x = height, y = after_stat(density)))+  
	  geom_histogram(bins = 9, fill = "gray", colour = "black")+
    geom_density(lwd = 1, colour = "blue")

# Mujeres
data %>%
  filter(age >= 18, male == 0) %>%
  ggplot(aes(x = height, y = after_stat(density)))+  
	  geom_histogram(bins = 8, fill = "gray", colour = "black")+
    geom_density(lwd = 1, colour = "red")
```

Desconocemos las varianzas por completo, así que utiliza un T-test con corrección de Welch (`var.equal = F` viene por defecto en el `t.test()`):

```{r}
# Hombres
male = data %>%
  filter(age >= 18, male == 1) %>%
  pull(height)

# Mujeres
female = data %>%
  filter(age >= 18, male == 0) %>%
  pull(height)

test = t.test(male, female, conf.level = 0.99)
test
```

Calcula el tamaño del efecto:

```{r}
eff = effectsize(test)
eff
```

Calcula la potencia (utiliza `pwr.t2n.test()`):

```{r}
pwr.t2n.test(n1 = 165,         # Tamaño muestra 1
             n2 = 187,         # Tamaño muestra 2
             d = eff$Cohens_d, # Tamaño del efecto
             sig.level = 0.99
)
```

**Conclusión**. Si hay diferencia en las alturas diferenciando por género para mayores de edad.

### Test de medidas repetidas.

Unos científicos examinaron la función de la vesícula biliar antes y después de una cirugía para detener el reflujo. Los autores midieron la funcionalidad de la vesícula biliar calculando la fracción de eyección de la vesícula biliar (GBEF) antes y después de la operación, cuyo objetivo es aumentar la GBEF. ¿Hay evidencia para concluir que la operación aumenta el GBEF? Datos en "gbef_long.txt".

```{r}
data = read.table("gbef_long.txt", header = T)
```

Plantea el test de hipótesis:

$$ \begin{cases} H_0 : \, \mu _1 \geq \mu _2 \\ H_a : \, \mu _1 < \mu _2  \end{cases} $$

Representa gráficamente los datos de cada muestra:

```{r}
# Hombres
data %>%
  filter(class == "Preop") %>%
  ggplot(aes(x = gbef, y = after_stat(density)))+  
	  geom_histogram(bins = 4, fill = "gray", colour = "black")+
    geom_density(lwd = 1, colour = "blue")

# Mujeres
data %>%
  filter(class == "Postop") %>%
  ggplot(aes(x = gbef, y = after_stat(density)))+  
	  geom_histogram(bins = 5, fill = "gray", colour = "black")+
    geom_density(lwd = 1, colour = "red")
```

No tienen pinta de normalidad...

Se trata de datos sin independencia, ya que son medidas repetidas sobre un mismo paciente... Por lo tanto, tenemos que aplicar un `t.test()` distinto (`paired = T`).

```{r}
# Hombres
antes = data %>%
  filter(class == "Preop") %>%
  pull(gbef)

# Mujeres
despues = data %>%
  filter(class == "Postop") %>%
  pull(gbef)

test = t.test(x = antes, y = despues, 
              conf.level = 0.95, 
              paired = TRUE, 
              alternative = "less")
test
```

Calcula el tamaño del efecto.

```{r}
eff = effectsize(test)
eff
```

Calcula la potencia.

```{r}
pwr.t.test(n = 12, d = -0.55, sig.level = 0.05, type = "paired", alternative = "less")
```

¿Cuántos sujetos necesitamos para mejorar la potencia al 95%?

```{r}
pwr.t.test(power = 0.95, 
           d = -0.55, sig.level = 0.05, 
           type = "paired", 
           alternative = "less")
```

**Conclusión**. Los datos no siguen normalidad y además el test no termina de ser concluyente.

### Test sobre la varianza de dos poblaciones.

Usa un test de ratio de varianzas para discutir si es razonable asumir igualdad de varianzas en el ejercicio de los Kung (¿Existe evidencia de que las varianzas por sexo son distintas?)

Plantea el test de hipótesis.

$$ \begin{cases} H_0 : \, \dfrac{\sigma_1^2}{\sigma_2^2} = 1 \\ H_a : \, \dfrac{\sigma_1^2}{\sigma_2^2} \neq 1  \end{cases} $$

```{r}
test = var.test(male, female, conf.level = 0.99)
test
```

**Conclusión**. Si, hay evidencias al 5% de significancia.

### Test de Poisson.

Un experto deportivo te asegura que un determinado equipo de futbol marca de media 2 o más goles por partido. Realiza un test de hipótesis con los datos del año pasado "goles.csv" y una significancia del 5%.

```{r}
data = read.csv("goles.csv")
```

Plantea el test de hipótesis (considera que la variable `Goles` sigue una distribución de Poisson):

$$ \begin{cases} H_0 : \, \lambda \geq 2 \\ H_a : \, \lambda < 2  \end{cases} $$

Representa gráficamente los datos.

```{r}
# Histograma y densidad
ggplot(data, aes(x = Goles))+  
	geom_bar(aes(y = after_stat(prop), group = 1),fill = "gray")+
  geom_density(lwd = 1)
```

Realiza un test de Poisson.

```{r}
# Suma muestral
suma = data %>%
  pull(Goles) %>%
  sum()

# Tamaño muestral
n = nrow(data)
  
# Test
test = poisson.test(suma, n, r=2, alternative = "less")

test
```

**Conclusión**. El equipo **no** marca de media 2 o más goles por partido.

### Test binomial (Bernoulli).

En una selección al azar de jurados las autoridades afirman que la probabilidad de que un elegido sea afroamericano es de $p = 0.5$ (coincidiendo con la proporción de afroamericanos en la población). Dispuesto a rechazar dicha afirmación, decides recoger los datos obtenidos en un juicio relacionado con el racismo. Datos en "juicio.xlsx". Realiza un test de hipótesis con una significancia del 5%.

```{r}
data = read_excel("juicio.xlsx", col_names = c("nombre","afroamericano"))
```

Representa gráficamente los datos.

```{r}
ggplot(data, aes(x=afroamericano, fill = as.factor(afroamericano)))+    
	geom_bar()
```

Realiza un test de hipótesis.

```{r}
# Suma muestral
suma = data %>%
  pull(afroamericano) %>%
  sum()

# Tamaño muestral
n = nrow(data)

test = binom.test(suma, n)
test
```

**Conclusión**. Si, hubo racismo.

### A/B Test (dos Bernoullis).

Una página web de venta de productos ha estudiado el número de conversiones de su página web actual (conversión = el usuario hace click en "comprar ahora"). Para aumentar el número de conversiones, rediseña el aspecto de su página web. La nueva página se prueba con un nuevo conjunto de usuarios, midiendo el número de conversiones. Datos en "ab_testing.csv". ¿Se puede concluir que la nueva página incrementa el número de conversiones?

```{r}
data = read.csv("ab_testing.csv")
```

Representa gráficamente los datos.

```{r}
ggplot(data = data, aes(x = page_design, fill = as.factor(has_clicked)))+
  geom_bar(position="fill")+
	coord_flip()

```

Realiza un test de proporciones.

```{r}
# Sumas muestrales
suma1 = data %>% 
	filter(page_design == "old") %>% 	
  pull(has_clicked) %>%
  sum()
suma2 = data %>% 
	filter(page_design == "new") %>% 	
  pull(has_clicked) %>%
  sum()

# Tamaños muestrales
n1 = data %>% 
	filter(page_design == "old") %>% 	
  pull(has_clicked) %>%
  length()
n2 = data %>% 
	filter(page_design == "new") %>% 	
  pull(has_clicked) %>%
  length()

prop.test(c(suma1, suma2), c(n1, n2), alternative = "less")
```

**Conclusión**. Si, la nueva página incrementa los clicks con una significancia del 5% (pero no del 1%).
