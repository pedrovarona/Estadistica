---
title: "Par치metros estad칤sticos"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Introducci칩n te칩rica.

Sea $X$ una variable aleatoria con funci칩n de distribuci칩n $F$ y funci칩n de densidad $f$, se definen los siguientes conceptos:

* Una **moda** es un m치ximo global de $f$.

* La **mediana** es $\min \{ x \, : \, F(x) \geq \frac{1}{2} \}$.

* El **$\alpha$-cuantil** es $\min \{ x \, : \, F(x) \geq \alpha \}$.

* La **esperanza** de una variable **discreta** es $E[X] = \sum _{-\infty} ^\infty xf(x)$.

* La **esperanza** de una variable **continua** es $E[X] = \int _{-\infty} ^\infty xf(x) dx$.

**Teorema** (Ley de los grandes n칰meros). Sea $(X_k )_{k\in\mathbb{N}}$ una sucesi칩n de variables aleatorias *id칠nticamente distribuidas*, *independientes* y con la misma esperanza $\mu < \infty$. Entonces:

$$ \overline{X}_n = \frac{1}{n} \sum _{k=1} ^n X_k \to \mu \text{ (convergencia casi segura)} $$

**Proposici칩n**. Dadas dos variables aleatorias $X$ e $Y$. Para todo $c\in\mathbb{R}$ se tiene que:

* $E[cX] = cE[X]$

* $E[X+Y] = E[X] + E[Y]$

* Si $X$ e $Y$ son independientes, entonces $E[X\cdot Y] = E[X]\cdot E[Y]$

**Teorema** (Ley del estad칤stico inconsciente). Sea $X$ una variable aleatoria y $g$ una funci칩n entonces:

* Si $X$ es discreta $E[g(X)] = \sum _{-\infty} ^\infty g(x)f(x)$

* Si $X$ es continua $E[g(X)] = \int _{-\infty} ^\infty g(x)f(x) dx$

Se define el **momento $k$-칠simo** de una variable aleatoria como:

$$ \alpha _k = E[X^k] $$

Si $\mu$ es la esperanza de una variable aleatoria, se define su **momento centrado $k$-칠simo** como:

$$ \mu _k = E[(X-\mu)^k] $$

Generalmente, se utiliza la notaci칩n de $\mu$ para la esperanza, $\sigma ^2$ para la varianza (momento centrado 2-칠simo) y $\sigma$ para la desviaci칩n t칤pica (ra칤z cuadrada de la varianza).

**Proposici칩n**. Dadas dos variables aleatorias $X$ e $Y$. Para todo $c\in\mathbb{R}$ se tiene que:

* $Var[X] = E[X^2] - E[X]^2$

* $Var[cX] = c^2 Var[X]$

* Si $X$ e $Y$ son independientes, entonces $Var[X+Y] = Var[X] + Var[Y]$

## Ejercicios

Calcular la esperanza de $X=$ "n췈 de caras obtenidas al lanzar 100 monedas".

```{r}
# Funci칩n de densidad.
fx = function(x){
  ifelse(x %in% 0:100, 1/2^100 * choose(100,x) , 0)
}

x = 0:100
sum(x*fx(x))
```

Un jugador gana 1 euro si al tirar un dado obtiene un 1 o un 3; pierde 2 euros si sale un 2, 4, 6; y gana 4 euros si sale un 5. 쮺u치l es la ganancia esperada? 쯁ugar칤as a este juego?

```{r}
# Primero determina la funci칩n de densidad de X = "Ganancia obtenida en el juego"
fx = function(x){
  if (x == -2){
    1/2
  }else if(x == 1){
    1/3
  }else if (x == 4){
    1/6
  }else{
    0
  }
}
fx = Vectorize(fx)

# Calcula la esperanza
x = c(-2,1,4)
sum(x*fx(x))
```

Realiza una simulaci칩n del juego para calcular la esperanza mediante la ley de los grandes n칰meros:

```{r}
# N칰mero de simulaciones
N = 1000

# Realizamos N simulaciones
experimentos = replicate(N,{
	# Lanzamos  dado
	dado = sample(1:6,1)
	
	# Valores de X:
	if (dado == 1 || dado == 3){
		x = 1
	}else if (dado == 5){
		x = 4
	}else{
		x = -2
	}
	x # Return valor de nuestra v.a. X
})

# Aproximamos la esperanza
mean(experimentos)
```

La polic칤a arresta a dos sospechosos. No hay pruebas suficientes para condenarlos y, tras haberlos separado, los visita a cada uno y les ofrece el mismo trato. Si uno confiesa y su c칩mplice no, el c칩mplice ser치 condenado a la pena total, diez a침os, y el primero ser치 liberado. Si uno calla y el c칩mplice confiesa, el primero recibir치 esa pena y ser치 el c칩mplice quien salga libre. Si ambos confiesan, ambos ser치n condenados a seis a침os. Si ambos lo niegan, todo lo que podr치n hacer ser치 encerrarlos durante un a침o por un cargo menor.

* En primer lugar, definimos la variable aleatoria $X=$ "n췈 de a침os de condena" considerando que $p$ es la probabilidad de que t칰 mientas y $q$ la probabilidad de que tu c칩mplice mienta. La funci칩n de densidad es:

$$ f(x) = \begin{cases} 
q(1-p) & \text{ si } x = 0 \\
pq & \text{ si } x = 1 \\
(1-q)(1-p) & \text{ si } x = 6 \\
(1-q)p & \text{ si } x = 10 
\end{cases} $$

* Calculamos la esperanza en funci칩n de $p$ para poder tomar una decisi칩n:

$$ E[X] = \begin{cases} 
6 - 6q & \text{ si } p = 0 \\
10 - 9q & \text{ si } p = 1 
\end{cases} $$

Como el valor esperado es siempre menor cuando $p=0$, la mejor opci칩n es confesar.

Se realizan lanzamientos sucesivos de una moneda hasta que salga cruz por primera vez. Entonces se detiene el juego, se cuenta el n칰mero de lanzamientos que se han producido, supongamos que han sido 洧녵. Entonces, el jugador obtiene 2^洧녵맔onedas. 쮺u치nto pagar칤as por jugar a este juego? **Intenta resolver el problema con simulaciones**

```{r}
# N칰mero de simulaciones
N = 1000

experimentos = replicate(N,{
	# Condiciones iniciales
	moneda = 0
	n = 0
	
	# Lanzamos  moneda
	while (moneda == 0){
		moneda = sample(0:1,1)
		n = n + 1
	}
	
	# Ganancias obtenidas
	2^n
})

# Aproximamos la esperanza
mean(experimentos)
```

Resultados extra침os? 쯇or qu칠? 

S칤, no se puede aplicar la ley de los grandes n칰meros porque la esperanza es infinita...